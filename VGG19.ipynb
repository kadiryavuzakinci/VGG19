{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYsgKmXlZvDqhW1ZEZLTdF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"maF5JdnXpCPr"},"outputs":[],"source":["!pip install torch"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","import torch.optim as optim\n","from sklearn.metrics import f1_score, confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"Hy4U0MwNp_zo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","  def __init__(self, data_dir, transform=None):\n","    self.data_dir = data_dir\n","    self.transform = transform\n","\n","    self.samples = []\n","    self.labels = []\n","\n","    for root, dirs, files in os.walk(data_dir):\n","      for filee in files:\n","\n","        if filee.endswith(\".jpg\") or filee.endswith(\".jpeg\"):\n","          image_path = os.path.join(root, filee)\n","\n","          label = filee.split(\"_\")[1]\n","          self.labels.append(label)\n","\n","  def __len__(self):\n","    return len(self.samples)\n","\n","  def __getitem__(self, idx):\n","\n","    image_path = self.samples[idx]\n","    image = Image.open(image_path)\n","\n","    if self.transform:\n","      image = self.transform(image)\n","\n","    label = self.labels[idx]\n","\n","    return image, label"],"metadata":{"id":"QrvwbQcfq4b1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, random_split\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)), # Resize images to VGG input size\n","    transforms.ToTensor(),\n","])\n","\n","custom_dataset = CustomDataset(data_dir='path_to_your_dataset', transform=transform)\n","\n","train_size = int(0.8 * len(custom_dataset))\n","val_size = len(custom_dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"],"metadata":{"id":"lQt7jhdZrfZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class VGG19(nn.Module):\n","    def __init__(self, num_classes):\n","        super(VGG19, self).__init__()\n","        self.features = nn.Sequential(\n","            # Convolutional layers\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(),\n","            nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(),\n","            nn.Linear(4096, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"3ZM3uvidtU0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"murMoKjexSif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = 10\n","vgg19_model = VGG19(num_classes)\n","vgg19_model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(vgg19_model.parameters(), lr=0.001)\n","\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","  vgg19_model.train()\n","  running_loss = 0.0\n","\n","  for inputs, labels in train_loader:\n","    inputs, labels = inputs.to(device), labels.to(device)\n","\n","    optimizer.zero_grad()\n","\n","    outputs = vgg19_model(inputs)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","\n","    train_loss = running_loss / len(train_loader)\n","\n","\n","    vgg19_model.eval()\n","    val_predictions = []\n","    val_targets = []\n","\n","    with torch.no_grad():\n","      for inputs, labels in val_laoder:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        outputs = vgg19_model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        val_predictions.extend(predicted.cpu().numpy())\n","        val_targets.extend(labels.cpu().numpy())\n","\n","    val_f1 = f1_score(val_targets, val_predictions, average='weighted')\n","    val_conf_matrix = confusion_matrix(val_targets, val_predictions)\n","\n","    print(f\"Epoch [{epoch + 1 }/{num_epochs}] - \"\n","          f\"Train Loss: {train_loss:.4f}, \"\n","          f\"Val F1 Score: {val_f1:.4f}\")\n","    print(\"Confusion Matrix:\")\n","    print(val_conf_matrix)\n","\n","print(\"Training Finished.\")\n","\n","\n","\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(val_conf_matrix, annot=True, fmt='d', cmap=\"Blues\",\n","            xticklabels=range(num_classes), yticklabels=range(num_classes))\n","\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()"],"metadata":{"id":"qFHFHQqew94X"},"execution_count":null,"outputs":[]}]}